---
title: "Modeling and Data Analysis for Pharmaceutical Sciences - Final Exam of Part 1"
output:
  html_document: default
  pdf_document: default
---

# Instructions

This final exam has 19 questions (11 for dataset 1 and 8 for dataset 2).

The duration of the exam is 90 minutes.

Some questions are multiple choice questions, but most of them are open questions which require you to provide a short answer.

You can answer either in English or in French.

Each question is worth 1 point.

Your grade will be computed considering a maximum of 19 points.

Good luck!


# Dataset 1: Peruvian Blood Pressure

This dataset consists of variables that are potentially related to blood pressure measurements of 39 Peruvians who have moved from rural high-altitude areas to urban lower-altitude areas. The variables in this dataset are listed as follows: 

- `Age`: Age in years
- `Years`: Years in urban area
- `Weight`: Weight in kg
- `Height`: Height in mm
- `Chin`: Chin skinfold
- `Forearm`: Forearm skinfold
- `Calf`: Calf skinfold
- `Pulse`: Resting pulse rate
- `Systol`: Systolic blood pressure

You work in a pharmaceutical company and want to conduct suitable statistical analyses to understand these data. In particular, you are asked to find variables that significantly contribute to high systolic blood pressure. 

You can load this dataset as follows:

```{r}
library(idarps)
data("PeruvianBP")
head(PeruvianBP)
```

Your department is in charge of studying the effects of being overweight on blood pressure (BP), where overweight subjects are defined as those with a Body Mass Index (BMI) greater than 25. Colleague A proposes to apply a t-test to assess whether overweight people have higher BP.

```{r}
# construct BMI
PeruvianBP$BMI = PeruvianBP$Weight / (PeruvianBP$Height/1000)^2
PeruvianBP$Overweight = as.numeric(PeruvianBP$BMI>25)
# define overweight subjects according to BMI
BP_not_overweight = PeruvianBP$Systol[PeruvianBP$Overweight == 0]
BP_overweight = PeruvianBP$Systol[PeruvianBP$Overweight == 1]

boxplot(BP_not_overweight, BP_overweight)
t.test(BP_not_overweight, BP_overweight, alternative = "less")
```

### Question 1

**Since the p-value is greater than 5%, Colleague A claims that this result proves that BP is equal between the two groups of overweight and non-overweight people. Do you agree with both the approach and the conclusion offered by Colleague A?**

**Solution:** No, I do not agree with this approach since you can never accept the null, and I do not agree with its conclusions as more variables should be considered to have comparable groups.

Colleague B says that the variable `Years` is known to be significant and should be taken into account. He thus proposes to fit the following linear regression model to test whether BMI has a significant impact on BP.
```{r}
mod0 = lm(BMI ~ Systol + Years, data = PeruvianBP) 
summary(mod0)
```

### Question 2

**Do you agree with the modelling approach proposed by Colleague B in `mod0`?**

**Solution:** No, the response and X should be flipped, and one should also consider more control variables.


Colleague C says that `mod0` is not correct and proposes the following model:

```{r}
mod1 = lm(Systol ~ BMI+Years+Age+Chin, data = PeruvianBP) 
summary(mod1)
```

### Question 3

**Colleague C found that years is not significant at 5%. But given the literature it should be. So he proposes to consider a significance level alpha=10%. What do you think of this approach?**

**Solution:** It is wrong as the significance level alpha should be fixed prior to the analysis.

Colleague D joins the discussion and proposes to include more variables into the model. She fits the following model:

```{r}
mod2 = lm(Systol ~ BMI+Years+Age+Chin+Forearm+Calf+Pulse, data = PeruvianBP) 
summary(mod2)

summary(mod1)
summary(mod2)

AIC(mod1)
AIC(mod2)
```

### Question 4

**Colleague D argues that `mod2` is better than `mod1` because the R^2 is higher and AIC is also higher. Do you agree with her argument? Justify your answer.**

**Solution:** No, because the R^2 is always larger for bigger models (so it is not reliable), and the model with smaller AIC should be preferable (finding that mod1 is better). 


Colleague E proposes to compute the AIC for a larger class of models, and pick the "best one" as follows:
```{r}
mod3 = lm(Systol ~ BMI+Years+Age+Chin+Forearm+Calf+Pulse+Weight+Height+Overweight, data = PeruvianBP) 
summary(mod3)

mod_aic = step(mod3, direction = "backward")

summary(mod_aic)

par(mfrow=c(1,2))
plot(fitted(mod_aic), resid(mod_aic))
qqnorm(resid(mod_aic))
qqline(resid(mod_aic))
```

### Question 5

**Colleague E asks about your opinion on `mod_aic` and whether this is appropriate or there may be evidence of model deficiencies. What would you suggest based on the two graphs above?**

1. We can't judge because we don't have enough data points to evaluate these two graphs. 
2. Such residual analysis graphs are not useful as we are considering a linear regression. They should only be used for a logistic regression.
3. The model seems appropriate as there is a good match between the model and the data.
4. These graphs suggest that the model does not provide a good fit because there are extreme values (e.g. larger than 20) in the residual graph. 

**Solution:** 3: the model seems appropriate.

### Question 6

**Colleague F wants to test whether height reduces BP. Based on `mod3`, he argues that one cannot reject the null at 5% significance level since the p-value is 0.07574. Do you agree?**

**Solution:** I do not agree, since the test is one-sided and thus the p-value should be divided by 2.


Colleague E is an expert on the topic and believes that `chin` cannot be associated with BP and should be removed from the model. She thus consider the following `mod4` and compute its AIC. 
```{r}
mod4 = lm(Systol ~ Years+ Weight+ Height+Overweight , data = PeruvianBP)
summary(mod4)

AIC(mod4)
AIC(mod_aic)
```

### Question 7

**She asks you if she can simply use `mod4` rather than `mod_aic` Motivate your answer.**

**Solution:** Since the difference of AIC is smaller than 2, it is ok to use mod4. Recall that AIC is computed based on the sample data, hence it is random and depends on the data. 

### Question 8

**Based on `mod4`, how would you interpret the estimated value of 1.93130 for the coefficient associated to `weight`?** 

**Solution:** Holding everything else constant, an increase of a kg in weight corresponds to an increase of 1.93130 in BP.


Colleague E is also interested in making predictions based on `mod4`.
She considers two new subjects who both moved to urban areas 2 years before and have the following characteristics:
```{r}
predict(mod4, data.frame(Years = 2, Weight = 53, Height = 1512, Overweight = 0))
predict(mod4, data.frame(Years = 2, Weight = 86, Height = 1651, Overweight = 1))
```

### Question 9
**Is the comparison above valid? Justify. What do these 2 predicted values mean?**

**Solution:** Yes, it is valid as we are not extrapolating. These are the predicted BP values for 2 people with such profiles.


Colleague E asks you to provide BP predictions for two twins who where involved in the study.
Twin A is 59 kg, 1660mm, and Twin B is 69kg, 1670mm. 
```{r}
predict(mod4, data.frame(Years = 20, Weight = 59, Height = 1535, Overweight = 1))
predict(mod4, data.frame(Years = 20, Weight = 59, Height = 1540, Overweight = 0))
```

### Question 10

**`mod4` predicts a BP of 114.73 and 122.27 for twin A and B, respectively. However, Colleague E is not satisfied about such a big difference in their BP. How can you explain the difference in predicted values between two similar persons?**

**Solution:** It is due to the presence of the binary variable "overweight" which has a large estimated value of -7.81074. So its change from 0 to 1 has a relevant impact on the predictions. 



McAllen (Texas) is the most overweight and obese city in the US with an average weight of 107 kg. For an average person with height of 1700mm (corresponding to a BMI of 37) who is 40 years old and has always lived in there, one would predict a BP of 186.3 using `mod4`. 
```{r}
predict(mod4, data.frame(Years = 40, Weight = 107, Height = 1700, Overweight = 1))
```

### Question 11

**Knowing that half of the residents in McAllen suffer from hypertension, what can you conclude from the prediction above?**

**Solution:** It is not a meaningful prediction as we are extrapolating both in terms of weight and height.


# Dataset 2: Breast Cancer 

This dataset consists of several clinical features observed or measured for 116 participants in a study of breast cancer. In particular, age, BMI, glucose, insulin and HOMA are recorded for each participant, as well as whether they have breast cancer or not. 

- `Age`: Age in years
- `BMI`: Body mass index in kg/$m^2$
- `Glucose`: Glucose in mg/dL
- `Insulin`: Insulin in $\mu$U/mL
- `HOMA`: Homeostasis model assessment 
- `Classification`: Presence of breast cancer (0 if no cancer, 1 if with cancer)


You work in a hospital and your goal is to develop a suitable model based on the available data in order to discover the significant features that contribute to the presence of breast cancer in women. 

You can load this dataset as follows:

```{r}
library(idarps)
data("BreastCancer")
head(BreastCancer)
```

Doctor A is interested in testing if a higher glucose value leads to a higher probability of getting breast cancer. He considers a logistic regression with all the available features as the covariates, and he obtains the following result: 

```{r}
mod1 = glm(Classification ~ ., family = binomial(), data = BreastCancer)
summary(mod1)
```


### Question 1

**Based on `mod1`, can you verify Doctor A's claim (i.e., a higher glucose value leads to a higher probability of getting breast cancer)? What is the p-value associated to this test?**

**Solution:** The p-value of this test is $0.000838/2=0.000419$. Therefore, at the 5% significance level, we can reject the null hypothesis and conclude that a higher glucose value leads to a higher probability of getting breast cancer. 


### Question 2

**Doctor B believes that a higher BMI should contribute to a higher probability of getting breast cancer. Based on `mod1`, can you determine the validity of Doctor B's claim? What is the p-value associated to this test?**

**Solution:** Since the estimated coefficient corresponding to BMI is smaller than 0, the p-value corresponding to this test is $1-0.007718/2=0.996141$. Therefore, at the 5% significance level, we fail to reject the null hypothesis and cannot conclude what Doctor B claims. 


Doctor C points out that age is known to have a nonlinear effect on the probability of getting breast cancer, in the sense that people between 40 to 60 years old have higher probability of getting breast cancer than the others. Doctor A argues that this is no problem because logistic regression is a nonlinear model.

### Question 3

**Do you agree with Doctor C that the nonlinear effect of age can be a potential problem in the use of `mod1`? Justify your answer.**

**Solution:** Yes I agree with Doctor C in the sense that the nonlinear effect of age can be a potential problem to use `mod1`. Indeed, `mod1` actually indicates a linear effect of age, and it shows that the probability of getting breast cancer decreases as the age increases. 


Given the results of `mod1`, Doctor B points out that although glucose is a significant variable, its estimated coefficient is very small (with a value of 0.09875). So Doctor B says that it is not necessary to include glucose into the model. 

### Question 4

**Do you agree with the argument of Doctor B to remove glucose from the model? Justify your answer.**

**Solution:** I do not agree with the argument of Doctor B. In `mod1`, glucose has a very small p-value of 0.000838, indicating that it has a statistically significant effect on the presence of breast cancer, so we should take it into consideration. Moreover, the coefficient value depends on the magnitude / scale of the variable. We can always rescale the glucose variable to obtain a larger coefficient value.


Doctor D joins the dicussion. She looks at `mod1` and says that we should actually remove insulin and HOMA from the model, because she believes that they are not associated with breast cancer. So she considers the following model: 

```{r}
mod2 = glm(Classification ~ Age + BMI + Glucose, family = binomial(), data = BreastCancer)
summary(mod2)
```

She also computes the AIC of both models, which gives: 

```{r}
AIC(mod1)
AIC(mod2)
```


### Question 5

**Which one of `mod1` and `mod2` is better? Is it possible to find a better model for this dataset?**

**Solution:** mod2 and mod1 are comparable in terms of AIC; recall that AIC is computed based on the sample data, hence it is random and depends on the data. It would be possible to find a better model. For example, we can try to consider interactions between variables and see if we can find a model with smaller AIC.


Doctor E also joins the discussion and he believes that we should use age in months instead of years. So he proposes to adjust `mod2` as follows:

```{r}
# Create the variable age in months
BreastCancer$Age_in_month = 12*BreastCancer$Age
```

```{r}
mod3 = glm(Classification ~ Age_in_month + BMI + Glucose, family = binomial(), data = BreastCancer)
summary(mod3)
```

Doctor D says that `mod3` is not as good as `mod2` because the corresponding coefficient is -0.02433 in `mod2` and now it becomes -0.002027 in `mod3`. Doctor D believes that this indicates that age is more important in `mod2` than in `mod3`.


### Question 6

**Do you agree with Doctor D that `mod2` is better than `mod3`? Do you agree that age is more important in `mod2` than in `mod3`? Justify your answer.**

**Solution:** I do not agree with Doctor D. In fact, the only difference between `mod2` and `mod3` is the rescaling of age, so they are actually equivalent. Moreover, since age has a p-value of 0.0843 in both models, it shows that age is equally important in `mod2` and `mod3`. 


Doctor B suspects that the data actually consider multiple measurements of the same persons at different ages. For example, she suspects that some people are measured several times a few years apart. Doctor B is worried that this could be a potential problem and she asks for your opinion. 


### Question 7

**Do you think that there could be a problem if the data are indeed collected in this way (i.e., multiple measurements of the same persons at different ages)?**

1. No, because logistic regression is a nonlinear model. 
2. No, because independence is not important since we account for the age effect already. 
3. Yes, because logistic regression considers non-normal data. 
4. Yes, because logistic regression assumes that data are independent. 
5. Maybe, it depends on the p-value for the age variable. 
6. It is impossible to answer given the available information.


**Solution:** 4: Yes, because logistic regression assumes that data are independent. 


The doctors decide to further assess the validity of `mod2` by computing its in-sample and out-of-sample classification accuracy. They obtain the following results:

```{r}
mod2_predict = mod2$fitted.values > 0.5
in_accuracy_mod2 = mean((BreastCancer$Classification == 1) == mod2_predict)
in_accuracy_mod2

library(boot)
cost = function(resp, pred){
  mean(resp == (pred > 0.5))
}

set.seed(123) # for reproducibility
out_accuracy_mod2 = cv.glm(BreastCancer, mod2, cost, K = 10)$delta[2]
out_accuracy_mod2
```


### Question 8

**Based on this study conducted in the USA, a group of Swiss researchers would like to use `mod2` to assess the risk of people getting breast cancer based on their characteristics (i.e., age, BMI, glucose). What is the expected accuracy (i.e., correct classification prediction) of using `mod2` on the Swiss population?**

1. The expected accuracy is difficult to assess since we are comparing data collected in the USA which may not be comparable to the Swiss population.
2. The expected accuracy is at least 0.6908442 (i.e., the out-of-sample accuracy) since it is a measured out of the sample.
3. The expected accuracy is at least 0.6908442 (i.e., the out-of-sample accuracy) because we are comparing data collected in the USA which may not be comparable to the Swiss population.
4. The expected accuracy is at least 0.7155172 (i.e., the in-sample accuracy) because we are comparing data collected in the USA which may not be comparable to the Swiss population.
5. The expected accuracy is between 0.6908442 and 0.7155172.

**Solution:** 1: The expected accuracy is difficult to assess since we are comparing data collected in the USA which may not be comparable to the Swiss population.
